{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youtube_transcript(url):\n",
    "    loader = YoutubeLoader.from_youtube_url(url, add_video_info=True)\n",
    "    documents = loader.load()\n",
    "    transcript = ' '.join([doc.page_content for doc in documents])\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"my favorite parts of my job is getting to interview people in the AI space it's super fun and I like to prepare as much as I can so I can ask some questions that they haven't been asked before however in order to prepare I found myself going through the same motions check their Twitter check their recent blog posts check YouTube interviews that they've done beforehand and this gets kind of time consuming and I thought to myself man this is a perfect use case for a language model and even better it would be awesome if I could host this on streamlit so that I could have an application that I could use whenever I wanted in this video we're going to cover how to make your own llm assisted researcher so you could save time on consolidating your own research you could use this for sales email inspiration recruiting calls job interview calls or if you're going to interview somebody yourself we're going to cover the main building blocks in a Jupiter notebook then we're going to go deploy this on streamlit and you're going to get the full code let's jump into it all right first thing we're going to do is import our packages we had a whole bunch of Lane chain stuff here between prompt templates our chat open AI because we're going to use gpt4 our recursive character text splitter which is a mouthful but that is going to split our document for us and then we're also going to use the load summarize chain now we're going to do this with custom prompts so it won't really be a summary per se but you'll see what we're talking about here in a second we're going to import tweepy which is our Twitter Library this is optional you don't need you don't need to do this if you don't want to we're going to import some scraping libraries and so requests beautiful soup and then also Mark downify we're going to bring in some YouTube videos and the transcripts from those and so we're going to bring in Lane chains document loader for YouTube and then we're just going to do some light environment variables let's run that and then so first thing we're going to do is load up our environment variable keys so these are all for the Twitter API again if you don't have this you don't need to do it you can just comment this piece of the code out but it'd be helpful if you did and then we have our open AI API key and in order to complete this tutorial we definitely should have that one all right so first thing we're going to do is we're going to pull our data from Twitter now this code may seem familiar because we did the same exact code in our Twitter AI bot tutorial which you can go check out the link that's over here but this isn't a tutorial about how to necessarily do the Twitter API so I'm going to kind of blow through this we're going to get the original tweets and so we're going to pass it a screen name so this would be like at Greg Cameron or at elad Gill we'll go through that we'll set up tweepee we're going to go grab the results themselves we're going to run through the results and I don't want to do any retweets or quote tweets and so I'm actually going to just continue on those I'm not going to add them to our list I only want to do the regular full Tweets we're going to sort them based on likes so the best ones come up at the top and then we're going to return the user tweets all right so here's the cool part I want to test this out here now for this tutorial we're going to pretend like we're going to go interview elad Gill the reason why I chose him is because he has a large online presence all right let's go ahead and try this one so we're going to get original tweets and we're going to pass in elad Gill's username and it is not Defined wonderful forgot to do that one let's give it a sec here all right so we have his first tweet well it's just the first 300 characters so more AI companies of sudden virality et cetera et cetera et cetera this would be probably his top tweet as of recently and we have a bunch of user tweets but this is just the uh the first 300 characters here next what I want to do is I want to pull some data from some websites so for this one I'm going to create another function called pull from websites and it's just going to take a URL it's going to make a request to that URL and then it's going to convert it into a beautiful soup object for us we're going to get the text and then one key tip that I learned from Eugene who runs core is to convert your text into markdown so this will remove all the HTML markup which is a bit adding a bit more noise than you'd like so there we go now what we're going to do here is I want to be able to pass multiple URLs in order to get the information from multiple places so for this one I'm going to say URLs are going to be elaguild.com because this actually happens to have a lot on his background and then also a blog post that he put together around defensibility and competition which is one of my favorites that I like and so we're going to create an empty string we're going to pass in our URLs and we're going to say for URL in URLs here's the text from the website and then go and add that text to your website data great so it's done and let's see what the first couple characters looks like so this looks like it's from its home his home page and he says welcome to Eli Gill's retro homepage who am I technology I'm an investor advisor so we get a lot of really good information about who this person is and we're gonna be able to make some really cool interview questions from this okay next thing I'm going to do is I want to pull data from YouTube so in order to do this one I'm going to use Lang chains document loader for YouTube videos we got our YouTube loader right here we're gonna say from YouTube url we're going to pass in the URL and then we're going to add some extra video info on here we're going to load our document and then I need to transform this instead of it being a document I just want to have some text because we're going to throw this in a prompt later so we're going to pass back the transcript let's run that and then here is our YouTube url that I looked at beforehand so I only have one URL here but I'm going to say for video URL in URLs video text equals go get the text and then we're going to add that to our empty string right there great let's see what this video transcript looks like all right I like to say that startups are an act of desperation now that we have all our data let's combine this into a single information block so I'm going to have a variable here called user information I'm going to pass and the tweets that we got I'm going to pass in the website data that we got and then also the YouTube data as well now we have our user information wonderful however this user information because we pulled websites and tweets and YouTube videos it's likely going to be a little long for our language model here so I need to split our text I'm going to initialize our recursive to character text splitter and I'm going to say chunk size of 20 000 which this is 20 000 characters which is going to be roughly 5 000 tokens so it's quite large what you'll want to do is you want to adjust this for whatever language model you're using depending on the costs and uh and all that and you know instead of a chunk over like 10 I'm going to do that just 20 let's go ahead and create that let's create our documents and let's see how many documents we have we now have three documents that user information has been split up into okay now here's where it starts to get pretty interesting because we're going to make some custom mapreduce prompts so in order to go over these three documents I need to tell the language model what information I want to extract from it now if we just use this standard load summarized chain it's going to say hey can you please summarize these three chunks for me and that's not quite what I want I want it to pull out interview questions for this person based off of those three different chunks now if you have more questions around the mapreduce method I have a whole video on openai workarounds for token limit lengths and I go over mapreduce in there in detail so for this map prompt let me step you through my thinking just a little bit you're an helpful AI bot that aids a user in research now I really like to assign a role to the AI so it knows who it's acting as below is information about a person and then we have a person's name here so this is a token that we will then insert elad Gill's name into the reason why I did that is because if I were to stay General blow is information about a person well it's it's not so bad I just want to give it more crisp instructions and so I'm going to pass the person's name in here information will include tweets interview transcripts and blog posts about elad your goal is to generate interview questions that we can ask about or go ask elab use specifics from the research when possible and then start of information end of information the reason why I put these two with percentage signs because I wanted to know when the e-lad information starts and when it ends because I'm going to be putting in a few more instructions here after the fact so I don't want to get confused with the information please respond with a list of a few interview questions based on the topics above and then I say your response okay this is our map prompt so it's going to go over those three different chunks and it's going to get us this information then with the response of those three chunks it's going to combine that or it's going to put that into the combined prompt right in the text section right here your helpful AI bought the AIDS in research you will be given a list of list of potential interview questions that we can ask elad so the reason why this isn't just raw text anymore this is going to be the interview questions that we had up in the map Step Up Above and so now we have interview questions and then really I should be saying your response let's do that great and you can see here with the prompt templates I kind of brushed over this but we have placeholders for text and we have placeholders for the person name person's name that's going to go right there then we're going to initialize our language model and I'm putting temperature 0.25 so this adds just a little bit more flare on top of the temperature rather than just zero but I encourage you to experiment you may bump this all the way up to one and have some fun with it but who knows model name gpt4 you can use 3.5 on here if you want to language model chain type mapreduce and then the cool part here is we're going to pass in our map prompt template which is our custom prompt from up above and then our combined prompt template let's run this Okay cool so the reason why that ran so quick is this just made our chain for us and it got us ready to start running it we won't actually run it until we pass in this information now we're going to pass in two different or two different parameters if you will the first one is going to be input documents so it's going to be our docs these are the three docs that we had up above which is information about elad and then we're going to pass in the person's name which is elad Gill here so that'll get dynamically well I guess not really dynamically but that'll get placed into our prompt templates now you may be asking well Greg why'd you put it here and why didn't you just put it in the prompt itself well because we're going to do some different people here in a second when we could streamline it and I didn't want to put in too many bad habits here let's run this and I will see when this comes out here it it does take a little bit so don't worry if it uh takes a long time for you all right so we just finished up here let's see what the output text is what key factors you consider when investing or advising AI startups can you share examples of successful AI startups that have bootstrapped their growth all right cool so we have looks like a good amount of questions here we have about 21 different questions now what I found by doing this a few times is that they're not necessarily copy and paste ready meaning you're not just going to go this and put on the front page of the New York Times however it should inspire a lot of really good questions within yourself and then you can add on your own voice or your own Flair on top of it all right so this is great in a Jupiter notebook it's really good for testing but the cool part is when we add it to streamlit so let's go add it to streamlit ourselves alright so now we're over on the streamlit side and we can't upload Jupiter notebooks to streamlit that would be kind of cool but it probably is a good thing because it'll get really messy so we're going to upload just a single script right here now you'd likely split this out into multiple scripts if you're doing this in production however for clarity and for conciseness um we're just doing one all right so we're going to import our packages just like beforehand this is basically just a port over of the Jupiter code that we had beforehand but it assumes a little bit more Edge case scenario as users start to input information so let's run through it we're going to import our packages just as beforehand we're going to load up our API Keys just as before we're going to get the original Tweets we're going to pull from the website and we're going to get the video transcripts these are just exact replicas of the of the code that we saw beforehand to go get our data well one thing I wanted to add was actually let the language model give us multiple types of feedback depending on which one the user selected so I wanted to have different response types you could have interview questions which is the example that we saw in the jupyter notebook but what if you just want a one page summary on this person maybe you don't want to interview questions you just want to know about them in the first place now based off of a radio button on streamlit which we'll see in just a second here we're going to get a different output back so for interview questions we're going to say your goal is to generate interview questions that we can ask them please respond with a list of a few interview questions based off of the topics above or for the one page summary your goal is to generate a one-page summary about them please respond with a few short paragraphs that would prepare somebody to talk to this person so depending on what the user selects we're going to go ahead and select one of these different items here and put that dynamically into our prompt okay now with our map prompt this is the same exact one you saw above except now we have the response type so this response type is going to get replaced with one of these two different selections here to pay depending on what the user says so we have our map prompt and we have a map prompt template okay great we have our combined prompt with our response prompt right there okay cool and then let's jump into the streamlit side of the house now in order to show this let me actually pull upstreamble so we can have it side by side all right so remember if you want to run a streamlit application all that you need to do is say streamlit run and then main.pi and I already navigated to where this code is being held here let's run this all right and then what we get popped up for us is actually the script that's running but I'm going to move this to the side just so we can see some more information for us here if you want a full tutorial on how streamlit works I have a intro to streamlit beginner tutorial that introduces The Core Concepts of stream load Lang chain and Link for that is in the description if you want to go check it out but here we have is our header so streamlined header llm assisted interview prep that is going to be this information up here now if I were to change this I will put a 2 right here and save that it's going to notice that I had a change here and I could either rerun it once or always rerun and I'm going to always rerun so that updates for me no matter what let me go ahead and delete that too because that's not helpful go ahead and run that okay cool and so I just have an intro here I'd say about some technologies that we're using I have a fun picture but then I introduced Larry the llm researcher so like I said beforehand I introduced a radio button and this radio button is going to be the output type that we want so do you want interview questions or do you want a one-page summary yeah and then what I have is different inputs for the user to input information about the person they want so for example I have the person's name I have the Twitter username and that is my username we don't we don't necessarily want that we don't do this the elad Gill e-lad Go and I'm just changing the placeholder within the text input for Twitter if I save that you can see that that gets changed for us right here these are videos about elad and then lastly we want um and there we are we have elad's information that's there so let's go over again one more time and look at the code behind this so that we could understand what's going on here so I won't go through every single line of code here but just to go through the big Parts I'm going to create a button indicator so over here we have this generate output button and once this is clicked the page is going to reload it's going to read it from top to bottom and if it is clicked then this button indicator is going to be true as opposed to false so if this button indicator is true it means the button that was it was just clicked and then I'm going to check to make sure that there's actually links that the user has submitted if not I'm going to throw a little bit of a fit and then I'm going to ask if there's the open AI key is set either it's an environment variable or they've placed it themselves if not it'll throw a fit as well and then we're going to go grab some data so we're going to get the user tweets the video text the website data from each one of the sources they said they gave and then we're going to put that into a user information just a big long string we're going to change that into Docs so it's going to split up into those three docks like we had beforehand could be more then we're going to go through and we're going to load up our language model so this uses the load llm function that we had up above we're going to create our summarize chain same exact thing as beforehand map reduce chain type and then we have our map prompt and our combined prompt as well now I put in a few breadcrumbs on here so we could see the app that was running so after this gets after the chain gets loaded up we're going to say sending to the llm because this is what's actually going to do the sending for us and if we scroll up above into our uh like say the Tweet one for example I say getting tweets right here so we can actually follow along with what the program is doing we're going to input our input documents which is going to be the user information docs that we had up above this is split from our user information we're going to put in the person's name which is just going to be a field that's going to be set right there and then we're going to take our response type now the cool part about this is this response types is the dictionary that we had up above and we're going to call the key of what is selected right here so if we go back up we have these interview questions that set right here corresponds to interview questions that's right here and then one page summary is the one page summary that's right here so we'll see what the user ends up selecting on that one all right now then we're going to just put a delineation for the output right here and then once the language model is done we're actually going to get the output text that gets sent right there all right and if you want to try this out yourself I put three different people on here between elad Sophia and Sean and you can go ahead and grab this information and input it into here but let's go and do this ourselves for this one since we've already done elad let's do Sean all right so I just input all of Sean's information his name Twitter Youtube webpage and let's go ahead and generate you know let's do a one-page summary on this case we're going to go ahead and generate a one-page summary about Sean generate all right now we have a response Sean Perry is a prominent entrepreneur investor and podcaster with significant social media presence especially Twitter nice so we have a pretty good background on who Sean is as a co-host in my first million yeah this is actually pretty good too if you're getting ready to meet Sean this would be a really awesome thing to get sped up in the first place let's go ahead and change this to interview questions and let's see what interview questions there are for Sophia all right just input Sophia's information let's go ahead and generate this all right we have a response here so what was the turning point that made you decide to launch nastygal how did you go about selecting the Vintage clothes with piecing you would sell on eBay nice okay all right so I've already made a repo for this but what I'm going to do is I'm going to add both these I'm going to commit and I'm going to push all right so that just went that just was pushed over there let's go check GitHub and let's go see we have llm research assistant so we have just right now just updated right there all right so what I'm going to do is I'm going to get the URL from my main.pi which is what you need to do for your streamlin apps and I'm actually going to go ahead and copy this one right here then I'm going to head over to streamlit and I'm going to sign in after I sign in I can see my other apps that I've done but I'm actually going to go ahead and create a new app so in for this one I'm just going to paste the GitHub URL and I want to just paste in the exact URL that I just had for the main.pi and I'm going to say deploy so after I say deploy it says your app is in the oven which is great because I like cookies and down here you can do the manage app and go ahead and click that and it's preparing your system and provisioning the Machine and everything in a second here you'll see that it's actually going to be updating all of the or I should say installing all the requirements that were in the requirement stock which I went ahead and did a pip freeze over here for you so you don't need to redo that if you go ahead and copy this code all right so let me come back to when this app is deployed all right so now our app has actually been deployed and you can tell because up at the URL that we have right here I might go clean this up but we'll see about that we have the same app that we had above and let's just double check that it works I'm actually going to do elad Guild on the summary because we haven't done a summary yet let's just go get his information all right so now we have the one page summary for elad let's go and insert at and go generate output one thing I did forgot to mention is that I you can see here that it does not have my openai API key and it does not have a Tweety as well so if you go up to the hamburger menu up above and you click view all apps let's go back to our apps homepage here and then on this app that we had just created I'm going to say settings and then I'm going to go to Secrets now on the Secret side this is where you can put your environment variables I'm going to go ahead and do that here so we uh so we have them all right so back here after I did my environment variables we insert the information again let's generate this one page summary getting tweets getting YouTube videos getting web pages Two web pages because there's two of them here and sending the llm for our one page summary all right we have a return here elad Gil's a highly respected AI expert in thought leader in the technology space often sharing his thoughts on Twitter and his blog nice this is a pretty good summary about them as well so now we have the information that we need to go and do a successful interview alright crew so that is how you consolidate the information gathering process and put it on a streamlit so that you can have a tool for your own personal use here if you have any questions please put them in the comments or if you have any general feedback at all I'd love to know what you think and as always please share any of the work that you end up building with me either via email or on Twitter I love to see it and I'd love for the community to see it all right crew we'll see you later\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_url = 'https://www.youtube.com/watch?v=zvoAMx0WKkw&list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5&index=22'\n",
    "get_youtube_transcript(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
